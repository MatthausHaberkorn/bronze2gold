[
  {
    "objectID": "posts/2025-11-08-hello-medaillon.html",
    "href": "posts/2025-11-08-hello-medaillon.html",
    "title": "From Bronze to Gold: a practical medallion blueprint",
    "section": "",
    "text": "The medallion pattern gives you clear seams in your platform:\n\nBronze — raw, append-only, minimal transforms (land it fast, keep lineage).\n\nSilver — cleaned & conformed (types, dedup, business keys).\n\nGold — analytics-ready (star schemas, aggregates, ML features).\n\nThose seams make testing, ownership, and incident response easier. Each layer gets its own storage, tables, schemas, and SLAs.\n\n\n\nUse any storage; the idea is consistent paths and naming:\n/bronze/&lt;source&gt;/&lt;ingest_date&gt;/part-*.parquet\n/silver/&lt;entity&gt;/v1/part-*.parquet\n/gold/&lt;mart&gt;/&lt;table&gt;/part-*.parquet\nSuggested table namespaces (example):\n\nbronze.orders_raw\nsilver.orders_curated\ngold.sales.fct_orders\n\nKeep raw immutable (append only), and make Silver idempotent so reruns don’t create duplicates.\n\n\n\n\nCommon upsert into Silver from a deduped Bronze view:\n-- Source is a deduplicated view of bronze\nMERGE INTO silver.orders_curated AS s\nUSING (\n  SELECT *\n  FROM bronze.orders_raw\n  QUALIFY ROW_NUMBER() OVER (\n    PARTITION BY order_id\n    ORDER BY ingest_ts DESC\n  ) = 1\n) AS b\nON s.order_id = b.order_id\nWHEN MATCHED THEN UPDATE SET\n  s.customer_id = b.customer_id,\n  s.order_ts    = b.order_ts,\n  s.status      = b.status,\n  s.amount      = b.amount,\n  s.src_ingest_ts = b.ingest_ts\nWHEN NOT MATCHED THEN INSERT *\n;\nWhy this is safe-ish: - Deduplication happens before the merge (one “winner” per key). - Update/insert paths are explicit; you can add column-level guards later (e.g., only update if b.order_ts &gt;= s.order_ts).\n\n\n\n\nSimple guardrails:\n\nBronze dedup: last record per business key (e.g., ROW_NUMBER() by ingest_ts).\n\nDeterministic filters: watermark by partition/date to avoid double counting backfills.\n\nChecks after write: assert distinct keys == count of rows for unique entities.\n\nPySpark example:\nfrom pyspark.sql import functions as F, Window as W\n\nbronze = spark.read.table(\"bronze.orders_raw\")\n\nw = W.partitionBy(\"order_id\").orderBy(F.col(\"ingest_ts\").desc())\nsilver_base = (\n    bronze\n    .withColumn(\"rn\", F.row_number().over(w))\n    .where(\"rn = 1\")\n    .drop(\"rn\")\n)\n\n# Basic data quality\nrow_count = silver_base.count()\nkey_count = silver_base.select(F.countDistinct(\"order_id\")).first()[0]\nassert key_count == row_count, f\"Non-unique order_id: keys={key_count}, rows={row_count}\"\n\n# Optional: partition pruning watermark (last 3 days as example)\nfrom datetime import datetime, timedelta\ncutoff = (datetime.utcnow() - timedelta(days=3)).isoformat()\nsilver_recent = silver_base.where(F.col(\"ingest_ts\") &gt;= cutoff)\n\nsilver_recent.createOrReplaceTempView(\"orders_recent\")\n\n\n\n\nSkew happens when a few keys are too popular, causing one reducer to work harder than the rest. Tactics:\n\nSalting: add a small random salt to heavy keys on both sides, then aggregate.\n\nAQE (Adaptive Query Execution): let the engine split skewed partitions at runtime.\n\nBroadcast small tables: avoid shuffles where possible.\n\nTiny salting sketch:\n-- Heavy key example: store_id with massive volume\nWITH salted_b AS (\n  SELECT\n    *,\n    CASE WHEN store_id IN (101, 202) THEN CAST(rand()*8 AS INT) ELSE 0 END AS salt\n  FROM silver.orders_curated\n),\nsalted_dim AS (\n  SELECT\n    d.*,\n    s.salt\n  FROM dim.stores d\n  -- explode salts 0..7 for heavy keys only (implementation varies)\n  CROSS JOIN (SELECT explode(sequence(0,7)) AS salt)\n)\nSELECT /*+ REPARTITION(200) */\n  b.order_id, d.region\nFROM salted_b b\nJOIN salted_dim d\n  ON b.store_id = d.store_id AND b.salt = d.salt;\n\n\n\n\n\nLand Bronze (CSV/JSON sample is fine).\n\nBuild a deduped view with ROW_NUMBER()/Window.\n\nMERGE INTO Silver from that view.\n\nAssert uniqueness and expected row counts.\n\nPublish Gold as an aggregate (daily sales, top N).\n\nGold example (daily revenue):\nCREATE OR REPLACE TABLE gold.sales.fct_daily_revenue AS\nSELECT\n  date_trunc('day', order_ts) AS day,\n  SUM(amount) AS revenue\nFROM silver.orders_curated\nGROUP BY 1;\n\n\n\n\n\nBronze is append-only; no transforms beyond minimal parsing.\n\nSilver merge reads from a deduped source view.\n\nIdempotency check (keys == rows) after the Silver write.\n\nAQE enabled; broadcast joins where appropriate.\n\nGold aggregates are recomputable (no irreversible logic).\n\nDocumentation: table owner, SLA, and lineage noted in the repo.\n\n\n\n\n\n\nAdd a post template so front-matter is consistent.\n\nWire giscus for comments and Plausible for analytics.\n\nPublish a follow-up: “MERGE INTO patterns: slowly changing keys vs. late arriving facts.”"
  },
  {
    "objectID": "posts/2025-11-08-hello-medaillon.html#minimal-layout-to-start",
    "href": "posts/2025-11-08-hello-medaillon.html#minimal-layout-to-start",
    "title": "From Bronze to Gold: a practical medallion blueprint",
    "section": "",
    "text": "Use any storage; the idea is consistent paths and naming:\n/bronze/&lt;source&gt;/&lt;ingest_date&gt;/part-*.parquet\n/silver/&lt;entity&gt;/v1/part-*.parquet\n/gold/&lt;mart&gt;/&lt;table&gt;/part-*.parquet\nSuggested table namespaces (example):\n\nbronze.orders_raw\nsilver.orders_curated\ngold.sales.fct_orders\n\nKeep raw immutable (append only), and make Silver idempotent so reruns don’t create duplicates."
  },
  {
    "objectID": "posts/2025-11-08-hello-medaillon.html#a-safe-merge-into-skeleton-delta-lake-style",
    "href": "posts/2025-11-08-hello-medaillon.html#a-safe-merge-into-skeleton-delta-lake-style",
    "title": "From Bronze to Gold: a practical medallion blueprint",
    "section": "",
    "text": "Common upsert into Silver from a deduped Bronze view:\n-- Source is a deduplicated view of bronze\nMERGE INTO silver.orders_curated AS s\nUSING (\n  SELECT *\n  FROM bronze.orders_raw\n  QUALIFY ROW_NUMBER() OVER (\n    PARTITION BY order_id\n    ORDER BY ingest_ts DESC\n  ) = 1\n) AS b\nON s.order_id = b.order_id\nWHEN MATCHED THEN UPDATE SET\n  s.customer_id = b.customer_id,\n  s.order_ts    = b.order_ts,\n  s.status      = b.status,\n  s.amount      = b.amount,\n  s.src_ingest_ts = b.ingest_ts\nWHEN NOT MATCHED THEN INSERT *\n;\nWhy this is safe-ish: - Deduplication happens before the merge (one “winner” per key). - Update/insert paths are explicit; you can add column-level guards later (e.g., only update if b.order_ts &gt;= s.order_ts)."
  },
  {
    "objectID": "posts/2025-11-08-hello-medaillon.html#idempotency-rerun-without-surprises",
    "href": "posts/2025-11-08-hello-medaillon.html#idempotency-rerun-without-surprises",
    "title": "From Bronze to Gold: a practical medallion blueprint",
    "section": "",
    "text": "Simple guardrails:\n\nBronze dedup: last record per business key (e.g., ROW_NUMBER() by ingest_ts).\n\nDeterministic filters: watermark by partition/date to avoid double counting backfills.\n\nChecks after write: assert distinct keys == count of rows for unique entities.\n\nPySpark example:\nfrom pyspark.sql import functions as F, Window as W\n\nbronze = spark.read.table(\"bronze.orders_raw\")\n\nw = W.partitionBy(\"order_id\").orderBy(F.col(\"ingest_ts\").desc())\nsilver_base = (\n    bronze\n    .withColumn(\"rn\", F.row_number().over(w))\n    .where(\"rn = 1\")\n    .drop(\"rn\")\n)\n\n# Basic data quality\nrow_count = silver_base.count()\nkey_count = silver_base.select(F.countDistinct(\"order_id\")).first()[0]\nassert key_count == row_count, f\"Non-unique order_id: keys={key_count}, rows={row_count}\"\n\n# Optional: partition pruning watermark (last 3 days as example)\nfrom datetime import datetime, timedelta\ncutoff = (datetime.utcnow() - timedelta(days=3)).isoformat()\nsilver_recent = silver_base.where(F.col(\"ingest_ts\") &gt;= cutoff)\n\nsilver_recent.createOrReplaceTempView(\"orders_recent\")"
  },
  {
    "objectID": "posts/2025-11-08-hello-medaillon.html#handling-skew-in-joins-the-90-second-version",
    "href": "posts/2025-11-08-hello-medaillon.html#handling-skew-in-joins-the-90-second-version",
    "title": "From Bronze to Gold: a practical medallion blueprint",
    "section": "",
    "text": "Skew happens when a few keys are too popular, causing one reducer to work harder than the rest. Tactics:\n\nSalting: add a small random salt to heavy keys on both sides, then aggregate.\n\nAQE (Adaptive Query Execution): let the engine split skewed partitions at runtime.\n\nBroadcast small tables: avoid shuffles where possible.\n\nTiny salting sketch:\n-- Heavy key example: store_id with massive volume\nWITH salted_b AS (\n  SELECT\n    *,\n    CASE WHEN store_id IN (101, 202) THEN CAST(rand()*8 AS INT) ELSE 0 END AS salt\n  FROM silver.orders_curated\n),\nsalted_dim AS (\n  SELECT\n    d.*,\n    s.salt\n  FROM dim.stores d\n  -- explode salts 0..7 for heavy keys only (implementation varies)\n  CROSS JOIN (SELECT explode(sequence(0,7)) AS salt)\n)\nSELECT /*+ REPARTITION(200) */\n  b.order_id, d.region\nFROM salted_b b\nJOIN salted_dim d\n  ON b.store_id = d.store_id AND b.salt = d.salt;"
  },
  {
    "objectID": "posts/2025-11-08-hello-medaillon.html#a-tiny-end-to-end-practice-loop",
    "href": "posts/2025-11-08-hello-medaillon.html#a-tiny-end-to-end-practice-loop",
    "title": "From Bronze to Gold: a practical medallion blueprint",
    "section": "",
    "text": "Land Bronze (CSV/JSON sample is fine).\n\nBuild a deduped view with ROW_NUMBER()/Window.\n\nMERGE INTO Silver from that view.\n\nAssert uniqueness and expected row counts.\n\nPublish Gold as an aggregate (daily sales, top N).\n\nGold example (daily revenue):\nCREATE OR REPLACE TABLE gold.sales.fct_daily_revenue AS\nSELECT\n  date_trunc('day', order_ts) AS day,\n  SUM(amount) AS revenue\nFROM silver.orders_curated\nGROUP BY 1;"
  },
  {
    "objectID": "posts/2025-11-08-hello-medaillon.html#a-checklist-you-can-reuse",
    "href": "posts/2025-11-08-hello-medaillon.html#a-checklist-you-can-reuse",
    "title": "From Bronze to Gold: a practical medallion blueprint",
    "section": "",
    "text": "Bronze is append-only; no transforms beyond minimal parsing.\n\nSilver merge reads from a deduped source view.\n\nIdempotency check (keys == rows) after the Silver write.\n\nAQE enabled; broadcast joins where appropriate.\n\nGold aggregates are recomputable (no irreversible logic).\n\nDocumentation: table owner, SLA, and lineage noted in the repo."
  },
  {
    "objectID": "posts/2025-11-08-hello-medaillon.html#what-to-do-next",
    "href": "posts/2025-11-08-hello-medaillon.html#what-to-do-next",
    "title": "From Bronze to Gold: a practical medallion blueprint",
    "section": "",
    "text": "Add a post template so front-matter is consistent.\n\nWire giscus for comments and Plausible for analytics.\n\nPublish a follow-up: “MERGE INTO patterns: slowly changing keys vs. late arriving facts.”"
  },
  {
    "objectID": "privacy.html",
    "href": "privacy.html",
    "title": "Privacy",
    "section": "",
    "text": "Kurzfassung: Keine Cookies, keine Tracker außer einer anonymen Seitenanalyse (optional)."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "From Bronze to Gold: a practical medallion blueprint\n\n\n\ndata-engineering\n\ndatabricks\n\nspark\n\ndelta\n\nmedallion\n\n\n\nA minimal, repeatable medallion layout with MERGE INTO patterns, idempotency checks, and a tiny PySpark example you can reuse.\n\n\n\n\n\n\nNov 8, 2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "bronze2gold.html",
    "href": "bronze2gold.html",
    "title": "bronze2gold",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "bronze2gold.html#quarto",
    "href": "bronze2gold.html#quarto",
    "title": "bronze2gold",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bronze → Gold",
    "section": "",
    "text": "From raw bronze to decision‑grade gold.\nPatterns, playbooks, and tiny reproducible demos in Data Engineering, Databricks, and Python.\nRead the blog About\n\n\n\n\nPractical recipes\nMERGE INTO patterns, idempotent pipelines, skew-busting, and observability you can copy.\n\n\n\nSmall, runnable demos\nShort posts with code you can execute locally or in notebooks.\n\n\n\nOpinionated, not dogmatic\nTools fade. Principles last. We keep both in view."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi—I’m Mat. I turn bronze into gold with clean pipelines, good tests, and a dash of duck (DB)."
  },
  {
    "objectID": "impressum.html",
    "href": "impressum.html",
    "title": "Impressum",
    "section": "",
    "text": "Trage hier deine Anbieterkennzeichnung gemäß § 5 TMG ein."
  }
]